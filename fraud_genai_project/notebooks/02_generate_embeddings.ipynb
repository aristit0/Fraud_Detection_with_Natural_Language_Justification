{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501a620b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import concat_ws\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Start Spark with Hive support and increased result size\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"FraudEmbeddingGeneration\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .config(\"spark.driver.memory\", \"16g\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"4g\") \\\n",
    "    .config(\"spark.executor.cores\", \"4\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"16\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Step 2: Load Hive table and prepare text input\n",
    "print(\"üì• Reading from Hive table datamart.fraud_transactions...\")\n",
    "df = spark.sql(\"SELECT * FROM datamart.fraud_transactions\")\n",
    "\n",
    "# Add a 'text' column to describe the transaction in natural language format\n",
    "df_text = df.withColumn(\"text\", concat_ws(\" \", \"user_id\", \"amount\", \"category\", \"country\"))\n",
    "\n",
    "# Step 3: Stream rows using toLocalIterator to avoid OOM\n",
    "texts = []\n",
    "print(\"‚öôÔ∏è Collecting rows from Spark with toLocalIterator...\")\n",
    "for row in df_text.select(\"text\").toLocalIterator():\n",
    "    texts.append(row[\"text\"])\n",
    "\n",
    "print(f\"‚úÖ Collected {len(texts)} records\")\n",
    "\n",
    "# Step 4: Load embedding model (GPU-enabled)\n",
    "print(\"üß† Loading model on GPU...\")\n",
    "model = SentenceTransformer(\"BAAI/bge-small-en-v1.5\")  # Uses CUDA if available\n",
    "\n",
    "# Step 5: Generate embeddings\n",
    "print(\"üöÄ Generating embeddings...\")\n",
    "start = time.time()\n",
    "embeddings = model.encode(texts, show_progress_bar=True, batch_size=64)\n",
    "duration = time.time() - start\n",
    "print(f\"‚úÖ Generated {len(embeddings)} embeddings in {duration:.2f} seconds\")\n",
    "\n",
    "# Optional: Save embeddings to local disk or vector database\n",
    "np.save(\"embeddings.npy\", embeddings)\n",
    "print(\"üíæ Saved embeddings to embeddings.npy\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
